---
title: "Data-Import"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE,
                      message = FALSE,
                      fig.align = "center", 
                      fig.height = 6, 
                      fig.width = 8)
```


```{r}
library("tidyverse")
library("knitr")
library("here")
```

This activity will give you practice with an efficient way to import data stored in a flat file format. Flat file formats are one of the most common formats for saving data because flat files can be read by a large variety of data related software. Flat file formats include Comma Separated Values (csv's), tab delimited files, fixed width files and more.

## `readr`

The [**`readr`**](https://readr.tidyverse.org/) R package contains simple, consistent functions for importing data saved as flat file documents. `readr` functions offer an alternative to base R functions that read in flat files. Compared to base R's `read.table()` and its derivatives, `readr` functions have several advantages. `readr` functions:

* are ~10 times faster
* return user-friendly tibbles
* have more intuitive defaults. No rownames, no `stringsAsFactors = TRUE`.

`readr` supplies several related functions, each designed to read in a specific flat file format. 

Function       | Reads
-------------- | --------------------------
`read_csv()`   | Comma separated values
`read_csv2()`  | Semi-colon separate values
`read_delim()` | General delimited files (single character)
`read_tsv()`   | Tab delimited values
`read_table()` | Space separated files
`read_table2()`| Like `read_table()` but allows any number of whitespace characters
`read_fwf()`   | Fixed width files

Here, we will focus on the `read_csv()` function, but the other functions work in a similar way. In most cases, you can use the syntax and arguments of `read_csv()` when using the other functions listed above.

`readr` is a core member of the tidyverse. It is loaded everytime you call `library("tidyverse")`.

<br>

***

<br>

## Sample data

A sample data set to import, `nimbus.csv`, can be dowloaded from the course website. The data set contains atmospheric ozone measurements of the southern hemisphere collected by NASA's NIMBUS-7 satellite in October 1985. The data set is of historical interest because it displays evidence of the hole in the ozone layer collected shortly after the hole was first reported.

## Importing Data

To import `nimbus.csv`, use the `readr` functions that reads `.csv` files, `read_csv()`. Set the first argument of `read_csv()` to a character string: the filepath from your _working directory_ to the `nimbus.csv` file.

## Problem 1: Reading the file

Use the `read_csv()` and `here()` functions to read the `nimbus.csv` file on your computer into an object called `nimbus`. Then view the results.

```{r, eval = FALSE}
nimbus <- # Read the file here
```

<br>

***

<br>

## Problem 2: Parsing NA values

If you examine `nimbus` closely, you will notice that the initial values in the `ozone` column are `.`. Can you guess what `.` stands for? The compilers of the nimbus data set used `.` to denote a missing value. In other words, they used `.` in the same way that R uses the `NA` value. 

If you'd like R to treat these `.` values as missing values (and you should) you will need to convert them to `NA`s. One way to do this is to ask `read_csv()` to parse `.` values as `NA` values when it reads in the data. To do this add the argument `na = "."` to `read_csv()`:

```{r eval = FALSE}
# Read file again using the na argument to recognize "." as a missing value.
```

You can set `na` to a single character string or a vector of character strings. `read_csv()` will transform every value listed in the `na` argument to an `NA` when it reads in the data.

<br>

***

<br>

## Problem 3: Specifying column types

If you run the code above and examine the results, you may now notice a new concern about the `ozone` column. The column has been parsed as character strings instead of numbers. 

When you use `read_csv()`, `read_csv()` tries to match each column of input to one of the basic data types in R. `read_csv()` generally does a good job, but here the initial presence of the character strings `.` caused `read_csv()` to misidentify the contents of the `ozone` column. You could correct this manually with R's `as.numeric()` function, or you could read the data in again, this time instructing `read_csv()` to parse the column as numbers.

To do this, add the argument `col_types` to `read.csv()` and set it equal to a list. Add a named element to the list for each column you would like to manually parse. The name of the element should match the name of the column you wish to parse.

So for example, if we wish to do something foolish and parse the `date` column into text string rather than a date, we could force `readr` to do so like this:

```{r eval = FALSE}
nimbus <- read_csv(#<path-to-your-nimbus.csv-file>
                   col_types = list(date = col_character())) # <-- BAD!!!!
```

To complete the code, set `ozone` equal to one of the functions below, each function instructs `read_csv()` to parse `ozone` as a specific type of data.

Type function     | Data Type
----------------- | -----------------------------------------
`col_character()` | character
`col_date()`      | Date
`col_datetime()`  | POSIXct (date-time)
`col_double()`    | double (numeric)
`col_factor()`    | factor
`col_guess()`     | let `readr` geuss (default)
`col_integer()`   | integer
`col_logical()`   | logical
`col_number()`    | numbers mixed with non-number characters
`col_numeric()`   | double or integer
`col_skip()`      | do not read this column
`col_time()`      | time

In our case, we would use the `col_double()` function to ensure that `ozone` is read a as number of type "double".

```{r eval = FALSE}
# Read file again: use the na argument, and specify that the ozone column should be read as a number.
```

<br>

***

<br>

## The hole in the ozone layer

Now that we have our data, we can use it to plot a picture of the hole in the ozone layer. Note that the "hole" in the ozone layer is the light regions around the south pole. The circular white area centered on the south pole shows where the satellite did not take measurements, and the small gray region shows the missing values.

Note: remove `eval = FALSE` from the chunk header below, and then delete this line.

```{r, eval = FALSE, fig.width = 6, fig.height = 6}

world <- map_data(map = "world")

ggplot() +
  geom_point(data = nimbus, aes(longitude, latitude, color = ozone)) +
  geom_path(data = world, aes(long, lat, group = group)) +
  coord_map("ortho", orientation = c(-90, 0, 0)) +
  scale_color_viridis_c(option = "magma", direction = -1) +
  theme_void() +
  theme(panel.background = element_rect(fill = "gray95"))
```

## Writing data

`readr` also contains functiomns for saving data. These functions parallel the read functions and each save a data frame or tibble in a specific file format.

Function            | Writes
------------------- | ----------------------------------------
`write_csv()`       | Comma separated values
`write_excel_csv()` | CSV that you plan to open in Excel
`write_delim()`     | General delimited files
`write_file()`      | A single string, written as is
`write_lines()`     | A vector of strings, one string per line
`write_tsv()`       | Tab delimited values

To use a write function, first give it the name of the data frame to save, then give it a filepath from your wqorking directory to the location where you would like to save the file. This filepath should end in the name of the new file. So we can save the clean `nimbus` data set as a csv in our working directory with.

```{r eval = FALSE}
write_csv(nimbus, path = "nimbus-clean.csv")
```

<br>

***

<br>

# Take Aways

The `readr` package provides efficient functions for reading and saving common flat file data formats.

Consider these packages for other types of data:

Package  | Reads
-------- | -----
haven    | SPSS, Stata, and SAS files
readxl   | excel files (.xls, .xlsx)
jsonlite | json
xml2     | xml
httr     | web API's
rvest    | web pages (web scraping)
DBI      | databases
sparklyr | data loaded into spark
